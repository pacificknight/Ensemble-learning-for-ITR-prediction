{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as ConstantKernel\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_excel('data_scaled.xlsx')\n",
    "y_index = ['itr']\n",
    "y = data[y_index]\n",
    "data.drop('itr', axis=1, inplace=True)\n",
    "X = data.drop('Interface', axis=1)\n",
    "# print(X[:10])\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed everything\n",
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost - all descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes, load_wine\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(learning_rate = 0.2, max_depth = 8, alpha = 50, colsample_bytree = 0.3, objective=\"reg:linear\", random_state=42)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_train_predict_a = xgb_model.predict(X_train)\n",
    "xgb_valid_predict_a = xgb_model.predict(X_valid)\n",
    "\n",
    "xgb_train_predict_a.shape = (553,1)\n",
    "xgb_valid_predict_a.shape = (139,1)\n",
    "\n",
    "print(xgb_train_predict_a.shape)\n",
    "print(xgb_valid_predict_a.shape)\n",
    "\n",
    "R2_train = r2_score(y_train, xgb_train_predict_a)\n",
    "mse_train = mean_squared_error(xgb_train_predict_a, y_train)\n",
    "rmse_train = math.sqrt(mse_train)\n",
    "\n",
    "R2_valid = r2_score(y_valid, xgb_valid_predict_a)\n",
    "mse_valid = mean_squared_error(xgb_valid_predict_a, y_valid)\n",
    "rmse_valid = math.sqrt(mse_valid)\n",
    "    \n",
    "print('R2_train is %f, R2_valid is %f, mse_train is %f,mse_valid is %f' % (\n",
    "       R2_train, R2_valid, rmse_train, rmse_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "importances = xgb_model.feature_importances_\n",
    "importances = {index: importance for index, importance in zip(X, importances)}\n",
    "importances = sorted(importances.items(), key=lambda x: x[1], reverse=True)\n",
    "importances2 = sorted(importances, key=lambda x: x[1], reverse=False)\n",
    "importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "rank = pd.DataFrame(importances2, columns=[\"descriptor\", \"score\"])\n",
    "print(rank.columns)\n",
    "\n",
    "fig = px.bar(\n",
    "    rank, \n",
    "    x='score', \n",
    "    y=\"descriptor\", \n",
    "    orientation='h',  \n",
    "    width=1200,\n",
    "    height=1000,\n",
    "    color='score',\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_tickfont_size=14,\n",
    "    xaxis=dict(\n",
    "        title='Score (importance)',\n",
    "        titlefont_size=22,\n",
    "        tickfont_size=15,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Descriptors',\n",
    "        titlefont_size=22,\n",
    "        tickfont_size=15,\n",
    "    ))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_index_selected = [feature for feature, importance in importances[:20]]\n",
    "X_index_selected.remove('fdensity')\n",
    "X_index_selected.remove('smass')\n",
    "X_index_selected.remove('fmass')\n",
    "print(X_index_selected)\n",
    "X_train_20 = X_train[X_index_selected]\n",
    "X_valid_20 = X_valid[X_index_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB with 17 descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(learning_rate = 0.2, max_depth = 9, alpha = 50, colsample_bytree = 0.3, objective=\"reg:linear\", random_state=42)\n",
    "\n",
    "xgb_model.fit(X_train_20, y_train)\n",
    "\n",
    "xgb_train_predict = xgb_model.predict(X_train_20)\n",
    "xgb_valid_predict = xgb_model.predict(X_valid_20)\n",
    "\n",
    "xgb_train_predict.shape = (553,1)\n",
    "xgb_valid_predict.shape = (139,1)\n",
    "\n",
    "print(xgb_train_predict.shape)\n",
    "print(xgb_valid_predict.shape)\n",
    "\n",
    "R2_train = r2_score(y_train, xgb_train_predict)\n",
    "mse_train = mean_squared_error(xgb_train_predict, y_train)\n",
    "rmse_train = math.sqrt(mse_train)\n",
    "\n",
    "R2_valid = r2_score(y_valid, xgb_valid_predict)\n",
    "mse_valid = mean_squared_error(xgb_valid_predict, y_valid)\n",
    "rmse_valid = math.sqrt(mse_valid)\n",
    "    \n",
    "print('R2_train is %f, R2_valid is %f, mse_train is %f,mse_valid is %f' % (\n",
    "       R2_train, R2_valid, rmse_train, rmse_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test data\n",
    "test_data = pd.read_excel('testdata-600K.xlsx')\n",
    "test_data = test_data[X_index_selected]\n",
    "print(type(test_data))\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "#load constructed systems to append predicted ITR by different models\n",
    "ms_ITR = pd.read_excel('test data - Copy.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_predict = xgb_model.predict(test_data)\n",
    "print(type(xgb_test_predict))\n",
    "print(len(xgb_test_predict))\n",
    "print('finished')\n",
    "xgb_ITR = pd.DataFrame(xgb_test_predict, columns=['xgb_ITR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17 descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krr = KernelRidge(kernel='rbf', alpha=0.013, gamma=0.1)\n",
    "krr.fit(X_train_20, y_train)\n",
    "\n",
    "krr_train_predict = krr.predict(X_train_20)\n",
    "krr_valid_predict = krr.predict(X_valid_20)\n",
    "print(krr_train_predict.shape)\n",
    "print(krr_valid_predict.shape)\n",
    "\n",
    "R2_train = r2_score(y_train, krr_train_predict)\n",
    "mse_train = mean_squared_error(krr_train_predict, y_train)\n",
    "rmse_train = math.sqrt(mse_train)\n",
    "\n",
    "R2_valid = r2_score(y_valid, krr_valid_predict)\n",
    "mse_valid = mean_squared_error(krr_valid_predict, y_valid)\n",
    "rmse_valid = math.sqrt(mse_valid)\n",
    "    \n",
    "print('R2_train is %f, R2_valid is %f, mse_train is %f,mse_valid is %f' % (\n",
    "       R2_train, R2_valid, rmse_train, rmse_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.shape)\n",
    "krr_test_predict = krr.predict(test_data)\n",
    "print(type(krr_test_predict))\n",
    "print(len(krr_test_predict))\n",
    "print('finished')\n",
    "krr_ITR = pd.DataFrame(krr_test_predict, columns=['krr_ITR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krr = KernelRidge(kernel='rbf', alpha=0.025, gamma=0.1)\n",
    "krr.fit(X_train, y_train)\n",
    "\n",
    "krr_train_predict_a = krr.predict(X_train)\n",
    "krr_valid_predict_a = krr.predict(X_valid)\n",
    "print(krr_train_predict_a.shape)\n",
    "print(krr_valid_predict_a.shape)\n",
    "\n",
    "R2_train = r2_score(y_train, krr_train_predict_a)\n",
    "mse_train = mean_squared_error(krr_train_predict_a, y_train)\n",
    "rmse_train = math.sqrt(mse_train)\n",
    "\n",
    "R2_valid = r2_score(y_valid, krr_valid_predict_a)\n",
    "mse_valid = mean_squared_error(krr_valid_predict_a, y_valid)\n",
    "rmse_valid = math.sqrt(mse_valid)\n",
    "    \n",
    "print('R2_train is %f, R2_valid is %f, mse_train is %f,mse_valid is %f' % (\n",
    "       R2_train, R2_valid, rmse_train, rmse_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17 descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed_everything(42)\n",
    "train_data = data.TensorDataset(torch.from_numpy(X_train_20.values), torch.from_numpy(y_train.values))\n",
    "trainloader = data.DataLoader(train_data, batch_size = X_train_20.shape[0], shuffle=True) # just one batch \n",
    "\n",
    "train_data2 = torch.from_numpy(X_train_20.values)\n",
    "valid_data = torch.from_numpy(X_valid_20.values)\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, dropout):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.linear1 = nn.Linear(num_features, 64)\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(64)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(64, 128)\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(128)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.linear3 = nn.Linear(128, 64)\n",
    "        \n",
    "        self.batch_norm4 = nn.BatchNorm1d(64)\n",
    "        self.dropout4 = nn.Dropout(dropout)\n",
    "        self.linear4 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.linear3(x))\n",
    "        \n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = self.linear4(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "dropout =  0.25\n",
    "# hidden_size = 128\n",
    "learning_rate = 0.0003\n",
    "Weight_Decay = 5e-5\n",
    "Epochs = 15000\n",
    "# Epochs = 8\n",
    "\n",
    "nn_model = Model(X_train_20.shape[1], dropout)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(nn_model.parameters(), lr= learning_rate, weight_decay=Weight_Decay)\n",
    "\n",
    "train_loss = []\n",
    "for epoch in range(Epochs):\n",
    "   \n",
    "    for batch in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = nn_model(batch[0].float())\n",
    "        loss = criterion(y_pred, batch[1].float())\n",
    "        if epoch % 100 == 0:\n",
    "            print('epochs: %d, training loss is : %f' % (epoch, loss))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "print('training loss:', np.mean(train_loss))\n",
    "epochs = list(range(Epochs))\n",
    "plt.plot(epochs, train_loss, 'g', label='Training loss')\n",
    "\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "nn_model.eval()\n",
    "nn_y_train_predict = nn_model(train_data2.float())\n",
    "nn_y_train_predict = nn_y_train_predict.detach().numpy()\n",
    "nn_y_valid_predict = nn_model(valid_data.float())\n",
    "nn_y_valid_predict = nn_y_valid_predict.detach().numpy()\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "R2_train = r2_score(nn_y_train_predict, y_train)\n",
    "R2_valid = r2_score(nn_y_valid_predict, y_valid)\n",
    "\n",
    "mse_train = mean_squared_error(nn_y_train_predict, y_train)   \n",
    "mse_valid = mean_squared_error(nn_y_valid_predict, y_valid)   \n",
    "print('R2_train is %f, rmse_train is %f' % (\n",
    "       R2_train, math.sqrt(mse_train)))\n",
    "print('R2_valid is %f, rmse_valid is %f' % (\n",
    "       R2_valid, math.sqrt(mse_valid)))\n",
    "print(type(nn_y_valid_predict))\n",
    "print(nn_y_train_predict.shape)\n",
    "print(nn_y_valid_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with test data\n",
    "test_data = test_data.to_numpy(np.float64)\n",
    "test_data2 = test_data\n",
    "# test_data = torch.from_numpy(test_data.values)\n",
    "test_data = torch.from_numpy(test_data).float()\n",
    "\n",
    "\n",
    "print(type(X_train.values))\n",
    "print(type(test_data.values))\n",
    "nn_y_test_predict = nn_model(test_data.float())\n",
    "nn_y_test_predict = nn_y_test_predict.detach().numpy()\n",
    "print(type(nn_y_test_predict))\n",
    "print(nn_y_test_predict)\n",
    "print(len(nn_y_test_predict))\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_ITR = pd.DataFrame(nn_y_test_predict, columns=['dnn_ITR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed_everything(42)\n",
    "train_data = data.TensorDataset(torch.from_numpy(X_train.values), torch.from_numpy(y_train.values))\n",
    "trainloader = data.DataLoader(train_data, batch_size = X_train.shape[0], shuffle=True) # just one batch \n",
    "\n",
    "train_data2 = torch.from_numpy(X_train.values)\n",
    "valid_data = torch.from_numpy(X_valid.values)\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, dropout):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.linear1 = nn.Linear(num_features, 32)\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(32)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(32, 64)\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(64)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.linear3 = nn.Linear(64, 32)\n",
    "        \n",
    "        self.batch_norm4 = nn.BatchNorm1d(32)\n",
    "        self.dropout4 = nn.Dropout(dropout)\n",
    "        self.linear4 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.linear3(x))\n",
    "        \n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = self.linear4(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "dropout =  0.3\n",
    "# hidden_size = 128\n",
    "learning_rate = 0.0004\n",
    "Weight_Decay = 6e-5\n",
    "Epochs = 15000\n",
    "# Epochs = 8\n",
    "\n",
    "nn_model = Model(X_train.shape[1], dropout)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(nn_model.parameters(), lr= learning_rate, weight_decay=Weight_Decay)\n",
    "\n",
    "train_loss = []\n",
    "for epoch in range(Epochs):\n",
    "   \n",
    "    for batch in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = nn_model(batch[0].float())\n",
    "        loss = criterion(y_pred, batch[1].float())\n",
    "        if epoch % 100 == 0:\n",
    "            print('epochs: %d, training loss is : %f' % (epoch, loss))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "print('training loss:', np.mean(train_loss))\n",
    "epochs = list(range(Epochs))\n",
    "plt.plot(epochs, train_loss, 'g', label='Training loss')\n",
    "\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "nn_model.eval()\n",
    "nn_y_train_predict_a = nn_model(train_data2.float())\n",
    "nn_y_train_predict_a = nn_y_train_predict_a.detach().numpy()\n",
    "nn_y_valid_predict_a = nn_model(valid_data.float())\n",
    "nn_y_valid_predict_a = nn_y_valid_predict_a.detach().numpy()\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "R2_train = r2_score(nn_y_train_predict_a, y_train)\n",
    "R2_valid = r2_score(nn_y_valid_predict_a, y_valid)\n",
    "\n",
    "mse_train = mean_squared_error(nn_y_train_predict_a, y_train)   \n",
    "mse_valid = mean_squared_error(nn_y_valid_predict_a, y_valid)   \n",
    "print('R2_train is %f, rmse_train is %f' % (\n",
    "       R2_train, math.sqrt(mse_train)))\n",
    "print('R2_valid is %f, rmse_valid is %f' % (\n",
    "       R2_valid, math.sqrt(mse_valid)))\n",
    "print(type(nn_y_valid_predict_a))\n",
    "print(nn_y_train_predict_a.shape)\n",
    "print(nn_y_valid_predict_a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17 descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(krr_train_predict.shape)\n",
    "print(nn_y_train_predict.shape)\n",
    "print(xgb_train_predict.shape)\n",
    "y_pred_train_18 = (krr_train_predict+nn_y_train_predict+xgb_train_predict)/3\n",
    "y_pred_final_18 = (krr_valid_predict+nn_y_valid_predict+xgb_valid_predict)/3\n",
    "print(y_pred_train_18.shape)\n",
    "print(y_pred_final_18.shape)\n",
    "\n",
    "R2_train = r2_score(y_pred_train_18, y_train)\n",
    "mse_train = mean_squared_error(y_pred_train_18, y_train) \n",
    "\n",
    "R2_valid = r2_score(y_pred_final_18, y_valid)\n",
    "mse_valid = mean_squared_error(y_pred_final_18, y_valid) \n",
    "\n",
    "print('R2_train is %f, rmse_train is %f' % (\n",
    "       R2_train, math.sqrt(mse_train)))\n",
    "print('R2_valid is %f, rmse_valid is %f' % (\n",
    "       R2_valid, math.sqrt(mse_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = (krr_train_predict_a+nn_y_train_predict_a+xgb_train_predict_a)/3\n",
    "y_pred_final = (krr_valid_predict_a+nn_y_valid_predict_a+xgb_valid_predict_a)/3\n",
    "print(y_pred_train.shape)\n",
    "print(y_pred_final.shape)\n",
    "\n",
    "R2_train = r2_score(y_pred_train, y_train)\n",
    "mse_train = mean_squared_error(y_pred_train, y_train) \n",
    "\n",
    "R2_valid = r2_score(y_pred_final, y_valid)\n",
    "mse_valid = mean_squared_error(y_pred_final, y_valid) \n",
    "\n",
    "print('R2_train is %f, rmse_train is %f' % (\n",
    "       R2_train, math.sqrt(mse_train)))\n",
    "print('R2_valid is %f, rmse_valid is %f' % (\n",
    "       R2_valid, math.sqrt(mse_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Congratulations! Done!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_valid)\n",
    "print(type(y_valid))\n",
    "print(y_pred_final)\n",
    "print(type(y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_valid, y_pred_final, label='All Descriptors')\n",
    "ax.scatter(y_valid, y_pred_final_18, label='Selected Descriptors')\n",
    "x1 = np.linspace(1, 200, 100)\n",
    "y1 = np.linspace(1, 200, 100)\n",
    "ax.plot(x1, y1, '--', color='k')\n",
    "leg = plt.legend(loc='best')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Experimental values ($10^{-9} $$m^{2}$K/W)\")\n",
    "plt.ylabel(\"Experimental values ($10^{-9} $$m^{2}$K/W)\")\n",
    "\n",
    "# plt.scatter(y_valid, y_pred_final)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join all ITR predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(nn_y_test_predict.shape)\n",
    "xgb_test_predict.shape = (88506,1)\n",
    "print(xgb_test_predict.shape)\n",
    "print(krr_test_predict.shape)\n",
    "average = (nn_y_test_predict+xgb_test_predict+krr_test_predict)/3\n",
    "en_ITR = pd.DataFrame(average, columns=['en_ITR'])\n",
    "print(en_ITR.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_ITR = pd.concat([ms_ITR, krr_ITR, xgb_ITR, dnn_ITR, en_ITR], join = 'outer', axis = 1) # combine all ITR with original data\n",
    "ms_ITR.to_excel(\"ms_ITR_600K_20210626.xlsx\") # write to excel\n",
    "print('congratulations! All done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "280.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
